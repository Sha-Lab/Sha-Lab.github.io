---
title: "Hello"
layout: splash
date: 2017-09-01T11:48:41-04:00
header:
  overlay_color: "#000"
  overlay_filter: "0.5"
  overlay_image: https://michelson.usc.edu/files/2016/05/USC-MCB-East-Entrance-new-name2.jpg
  cta_label: "Start Learning!"
  cta_url: "http://shalab.ml/blog/"
  #caption: ""
excerpt: "We do machine learning."
intro: 
  - excerpt: 'The mission of <b> ShaLab </b> is to develop principled methods <br> for machine learning and artificial intelligence. <br> <br> We work on research problems in core machine learning (ML), reinforcement learning (RL), computer vision, natural language processing, and life sciences.'

feature_row:
  - image_path: 
    alt: <!--"Core Machine Learning"-->
    title: "Core Machine Learning"
    excerpt: "Deep learning, transfer learning, domain adaptation, multi-task learning, zero-shot learning, metric learning, generative models, probabilistic graphical models, optimization, kernel methods. <br> [Learn more.](https://shalab.ml/publications/)"
  - image_path: 
    title: "Reinforcement Learning"
    excerpt: "Deep RL, transfer learning in RL, multi-agent RL, exploration, state abstraction. <br> [Learn more.](https://shalab.ml/publications/)"
  - image_path: 
    title: "Computer Vision"
    excerpt: "Vision and language, video summarization, image captioning, image segmentation, object recognition. <br> [Learn more.](https://shalab.ml/publications/)"
  - image_path: 
    title: "Natural Language Processing"
    excerpt: "Language modeling, dialogue generation, sequence tagging. <br> [Learn more.](https://shalab.ml/publications/)"
  - image_path: 
    title: "Life Sciences"
    excerpt: "Cancer therapy, precision medicine. <br> [Learn more.](https://shalab.ml/publications/)"

feature_row2:
  - image_path: http://vladlen.info/wp-content/uploads/FSO-1.jpg
    title: "Synthesized Policies for Transfer and Adaptation across Tasks and Environments"
    excerpt: 'The ability to transfer in reinforcement learning is key towards building an agent of general artificial intelligence. In this paper, we consider the problem of learning to simultaneously transfer across both environments (ENV) and tasks (TASK), probably more importantly, by learning from only sparse (ENV, TASK) pairs out of all the possible combinations. We propose a novel compositional neural network architecture which depicts a meta rule for composing policies from environment and task embeddings.'
    url: "https://sites.google.com/view/nips2018-synpo"
    btn_label: "Project Page"
    btn_class: "btn--inverse"
    url: "http://hexianghu.com/pdf/hexiang2018synpo.pdf"
    btn_label: "Paper"
    btn_class: "btn--inverse"

feature_row3:
  - image_path: http://visualqa.org/static/img/challenge.png
    title: "Cross-Modal and Hierarchical Modeling of Video and Text"
    excerpt: 'Visual data and text data are composed of information at multiple granularities. A video can describe a complex scene that is composed of multiple clips or shots, where each depicts a semantically coherent event or action. Similarly, a paragraph may contain sentences with different topics, which collectively conveys a coherent message or story. In this paper, we investigate the modeling techniques for such hierarchical sequential data where there are correspondences across multiple modalities. Specifically, we introduce hierarchical sequence embedding (hse), a generic model for embedding sequential data of different modalities into hierarchically semantic spaces, with either explicit or implicit correspondence information.'
    url: "https://arxiv.org/pdf/1810.07212.pdf"
    btn_label: "Paper"
    btn_class: "btn--inverse"
---

{% include feature_row id="intro" type="center" %}

{% include feature_row %}

{% include feature_row id="feature_row2" type="left" %}

{% include feature_row id="feature_row3" type="right" %}
