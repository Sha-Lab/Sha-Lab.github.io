---
title: "Hello."
layout: splash
date: 2017-09-01T11:48:41-04:00
header:
  overlay_color: "#000"
  overlay_filter: "0.5"
  overlay_image: https://michelson.usc.edu/files/2016/05/USC-MCB-East-Entrance-new-name2.jpg
  cta_label: "Start Learning!"
  cta_url: "http://shalab.ml/blog/"
  #caption: ""
excerpt: "We like machine learning a lot."
intro: 
  - excerpt: 'The mission of <b> ShaLab </b> is to develop principled methods <br> for machine learning and artificial intelligence. <br> <br> We work on research problems in core machine learning (ML), reinforcement learning (RL), computer vision, natural language processing, and life sciences.'

feature_row:
  - image_path: 
    alt: <!--"ML and RL"-->
    title: "ML and RL"
    excerpt: "Analysing images, chatbots, answering complex queries, summarizing videos, and understanding speech. [Learn more.](https://shalab.ml/publications/)"
  - image_path: 
    alt: <!--"Computer Vision"-->
    title: "Computer Vision"
    excerpt: "With our collaborators at the Michelson Center for Transformative Medicine. [Learn more.](https://shalab.ml/publications/)"
  - image_path: 
    title: "Natural Language Processing"
    excerpt: "Powerful statistical models and difficult optimization problems. [Learn more.](https://shalab.ml/publications/)"
  - image_path: 
    title: "Life Sciences"
    excerpt: "Powerful statistical models and difficult optimization problems. [Learn more.](https://shalab.ml/publications/)"

feature_row2:
  - image_path: http://vladlen.info/wp-content/uploads/FSO-1.jpg
    alt: "Semantic Segmentation"
    title: "LabelBank: Revisiting Global Perspectives for Semantic Segmentation"
    excerpt: 'Semantic segmentation requires a detailed labeling of image pixels by object category. Information derived from local image patches is necessary to describe the detailed shape of individual objects. However, this information is ambiguous and can result in noisy labels. Global inference of image c...'
    url: "https://arxiv.org/pdf/1703.09891"
    btn_label: "Read Paper"
    btn_class: "btn--inverse"

feature_row3:
  - image_path: http://visualqa.org/static/img/challenge.png
    alt: "VQA"
    title: "Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets"
    excerpt: 'Visual question answering (QA) has attracted a lot of attention lately, seen essentially as a form of (visual) Turing test that artificial intelligence should strive to achieve. In this paper, we study a crucial component of this task: how can we design good datasets for the task? We focus on the...'
    url: "https://arxiv.org/pdf/1704.07121.pdf"
    btn_label: "Read Paper"
    btn_class: "btn--inverse"
---

{% include feature_row id="intro" type="center" %}

{% include feature_row %}

{% include feature_row id="feature_row2" type="left" %}

{% include feature_row id="feature_row3" type="right" %}
