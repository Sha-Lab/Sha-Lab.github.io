---
title: "Hello"
layout: splash
date: 2017-09-01T11:48:41-04:00
header:
  overlay_color: "#000"
  overlay_filter: "0.5"
  overlay_image: https://michelson.usc.edu/files/2016/05/USC-MCB-East-Entrance-new-name2.jpg
  cta_label: "Start Learning!"
  cta_url: "http://shalab.ml/blog/"
  #caption: ""
excerpt: "We do machine learning."
intro: 
  - excerpt: 'The mission of <b> ShaLab </b> is to develop principled methods <br> for machine learning and artificial intelligence. <br> <br> We work on research problems in core machine learning (ML), reinforcement learning (RL), computer vision, natural language processing, and life sciences.'

feature_row:
  - image_path: 
    alt: <!--"Core Machine Learning"-->
    title: "Core Machine Learning"
    excerpt: "Deep learning, transfer learning, domain adaptation, multi-task learning, zero-shot learning, metric learning, generative models, probabilistic graphical models, optimization, kernel methods. <br> [Learn more.](https://shalab.ml/publications/)"
  - image_path: 
    title: "Reinforcement Learning"
    excerpt: "Deep RL, transfer learning in RL, multi-agent RL, exploration, state abstraction. <br> [Learn more.](https://shalab.ml/publications/)"
  - image_path: 
    title: "Computer Vision"
    excerpt: "Vision and language, video summarization, image captioning, image segmentation, object recognition. <br> [Learn more.](https://shalab.ml/publications/)"
  - image_path: 
    title: "Natural Language Processing"
    excerpt: "Language modeling, dialogue generation, sequence tagging. <br> [Learn more.](https://shalab.ml/publications/)"
  - image_path: 
    title: "Life Sciences"
    excerpt: "Cancer therapy, precision medicine. <br> [Learn more.](https://shalab.ml/publications/)"

feature_row2:
  - image_path: http://vladlen.info/wp-content/uploads/FSO-1.jpg
    title: "Synthesized Policies for Transfer and Adaptation across Tasks and Environments"
    excerpt: 'In this paper, we consider the problem of learning to simultaneously transfer across both environments (ENV) and tasks (TASK), probably more importantly, by learning from only sparse (ENV, TASK) pairs out of all possible combinations. We propose a compositional neural network which depicts a meta rule for composing policies from the environment and task embeddings.'
    url: "https://sites.google.com/view/nips2018-synpo"
    btn_label: "Project Page"
    btn_class: "btn--inverse"
    url: "http://hexianghu.com/pdf/hexiang2018synpo.pdf"
    btn_label: "Paper"
    btn_class: "btn--inverse"

feature_row3:
  - image_path: http://visualqa.org/static/img/challenge.png
    alt: "VQA"
    title: "Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets"
    excerpt: 'Visual question answering (QA) has attracted a lot of attention lately, seen essentially as a form of (visual) Turing test that artificial intelligence should strive to achieve. In this paper, we study a crucial component of this task: how can we design good datasets for the task? We focus on the...'
    url: "https://arxiv.org/pdf/1704.07121.pdf"
    btn_label: "Paper"
    btn_class: "btn--inverse"
---

{% include feature_row id="intro" type="center" %}

{% include feature_row %}

{% include feature_row id="feature_row2" type="left" %}

{% include feature_row id="feature_row3" type="right" %}
