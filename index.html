---
title: "Home"
layout: splash
date: 2017-09-01T11:48:41-04:00
header:
  overlay_color: "#000"
  overlay_filter: "0.5"
  overlay_image: /assets/imgs/michelson.jpg
  cta_label: "Start Learning!"
  cta_url: "http://shalab.ml/blog/"
image_description: "asdf"
excerpt: "We do machine learning."
intro: 
  - excerpt: 'The mission of <b> ShaLab </b> is to develop principled methods <br> for machine learning and artificial intelligence. <br> <br> We work on research problems in core machine learning (ML), reinforcement learning (RL), vision, natural language processing, and life sciences.'


feature_row:
  - image_path: http://www-scf.usc.edu/~weilunc/img/zero1.png
    title: <a href="/research/ml_rl/">ML/RL</a>
    excerpt: "Deep learning, transfer learning, domain adaptation, multi-task learning, zero-shot learning, multi-agent RL, exploration, state abstraction, metric learning, generative models, probabilistic graphical models, optimization, kernel methods."
  - image_path: http://hexianghu.com/images/projects/2018/hexiang2018ansemb.png
    title: <a href="/research/vision/">Vision</a>
    excerpt: "Vision and language, video summarization, image captioning, image segmentation, object recognition."
  - image_path: http://hexianghu.com/images/projects/2018/hexiang2018adaptation.png
    title: <a href="/research/nlp/">Natural Language Processing</a>
    excerpt: "Language modeling, dialogue generation, sequence tagging."


feature_row2:
  - image_path: http://hexianghu.com/images/projects/2018/hexiang2018synpo.png
    title: "Synthesized Policies for Transfer and Adaptation across Tasks and Environments"
    excerpt: 'The ability to transfer in reinforcement learning is key towards building an agent of general artificial intelligence. In this paper, we consider the problem of learning to simultaneously transfer across both environments (ENV) and tasks (TASK), probably more importantly, by learning from only sparse (ENV, TASK) pairs out of all the possible combinations. We propose a novel compositional neural network architecture which depicts a meta rule for composing policies from environment and task embeddings.'
    url: "https://sites.google.com/view/nips2018-synpo"
    btn_label: "Project Page"
    btn_class: "btn--inverse"

feature_row3:
  - image_path: http://hexianghu.com/images/projects/2018/bowen2018hse.png
    title: "Cross-Modal and Hierarchical Modeling of Video and Text"
    excerpt: 'Visual data and text data are composed of information at multiple granularities. A video can describe a complex scene that is composed of multiple clips or shots, where each depicts a semantically coherent event or action. Similarly, a paragraph may contain sentences with different topics, which collectively conveys a coherent message or story. In this paper, we investigate the modeling techniques for such hierarchical sequential data where there are correspondences across multiple modalities. Specifically, we introduce hierarchical sequence embedding (hse), a generic model for embedding sequential data of different modalities into hierarchically semantic spaces, with either explicit or implicit correspondence information.'
    url: "https://arxiv.org/abs/1810.07212"
    btn_label: "Paper"
    btn_class: "btn--inverse"
---

{% include feature_row id="intro" type="center" %}

{% include feature_row %}

{% include feature_row id="feature_row2" type="left" %}

{% include feature_row id="feature_row3" type="right" %}
