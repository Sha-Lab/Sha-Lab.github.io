---
title: "Home"
layout: splash
date: 2017-09-01T11:48:41-04:00
header:
  overlay_color: "#000"
  overlay_filter: "0.5"
  overlay_image: https://michelson.usc.edu/files/2016/05/USC-MCB-East-Entrance-new-name2.jpg
  cta_label: "Start Learning!"
  cta_url: "http://shalab.ml/blog/"
  #caption: ""
excerpt: "is where the GPUs are."
intro: 
  - excerpt: 'The mission of <b> ShaLab </b> is to develop principled methods <br> for machine learning and artificial intelligence. <br> <br> We work on research problems in core machine learning (ML), reinforcement learning (RL), computer vision, natural language processing, and life sciences.'

feature_row:
  - image_path: 
    alt: <!--"Core Machine Learning"-->
    title: "Core Machine Learning"
    excerpt: "Deep learning, transfer learning, domain adaptation, multi-task learning, zero-shot learning, metric learning, generative modeling, optimization, kernel methods. <br> [Learn more.](https://shalab.ml/publications/)"
  - image_path: 
    title: "Reinforcement Learning"
    excerpt: "Deep RL, transfer learning in RL, multi-agent RL, exploration, state abstraction. <br> [Learn more.](https://shalab.ml/publications/)"
  - image_path: 
    title: "Computer Vision"
    excerpt: "Vision and language, video summarization, image captioning, image segmentation, object recognition. <br> [Learn more.](https://shalab.ml/publications/)"
  - image_path: 
    title: "Natural Language Processing"
    excerpt: "Language modeling, dialogue generation, sequence tagging. <br> [Learn more.](https://shalab.ml/publications/)"

feature_row2:
  - image_path: http://vladlen.info/wp-content/uploads/FSO-1.jpg
    alt: "Semantic Segmentation"
    title: "LabelBank: Revisiting Global Perspectives for Semantic Segmentation"
    excerpt: 'Semantic segmentation requires a detailed labeling of image pixels by object category. Information derived from local image patches is necessary to describe the detailed shape of individual objects. However, this information is ambiguous and can result in noisy labels. Global inference of image c...'
    url: "https://arxiv.org/pdf/1703.09891"
    btn_label: "Read Paper"
    btn_class: "btn--inverse"

feature_row3:
  - image_path: http://visualqa.org/static/img/challenge.png
    alt: "VQA"
    title: "Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets"
    excerpt: 'Visual question answering (QA) has attracted a lot of attention lately, seen essentially as a form of (visual) Turing test that artificial intelligence should strive to achieve. In this paper, we study a crucial component of this task: how can we design good datasets for the task? We focus on the...'
    url: "https://arxiv.org/pdf/1704.07121.pdf"
    btn_label: "Read Paper"
    btn_class: "btn--inverse"
---

{% include feature_row id="intro" type="center" %}

{% include feature_row %}

{% include feature_row id="feature_row2" type="left" %}

{% include feature_row id="feature_row3" type="right" %}
